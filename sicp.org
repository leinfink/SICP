#+TITLE: Structure and Interpretation of Computer Programs
#+STARTUP: nohideblocks

#+name: commentify
#+begin_src emacs-lisp :var result="" :exports none
(concat ";=> " (format "%s" result))
#+end_src

#+RESULTS: commentify
: ;=> 

/Attribution:/ Harold Abelson and Gerald Jay Sussman with Julie Sussman, foreword by Alan J. Perlis, ©1996 by The Massachusetts Institute of Technology, licensed under the Creative Commons Attribution-ShareAlike 4.0 International License (CC BY-SA 4.0). Notes, (modified or adjusted) excerpts, and exercises by @leinfink.

* TODO Chapter 1 [44%]
:PROPERTIES:
:header-args:scheme: :session *sicp1* :post commentify(*this*)
:COOKIE_DATA: todo recursive
:END:
** DONE 1.1 The Elements of Programming [8/8]
  :PROPERTIES:
  :COOKIE_DATA: todo recursive
  :END:

- primitive expressions
- means of combination
- means of abstraction

- procedures
- data
  
*** 1.1.1 Expressions
- /primitive expressions/ can get combined into combinations with operators and operands
- the value of a combination is obtained by /applying/ the procedure that is the value of the operator  to the arguments that are the values of the operands
- Lisp: /prefix notation/, allows for an aribtrary number of arguments and for easy nesting
  
*** 1.1.2 Naming and the Environment
- /names/ identify /variables/ whose /value/ is a computational object
- these associations are stored in the /environment/
  
*** 1.1.3 Evaluating Combinations
- general evaluation rule (for combinations) :: 1. /Evaluate/ the subexpressions of the combination. 2. /Apply/ the procedure that is the value of the leftmost subexpression (the operator) to the arguments that are the values of the other subexpression.
  - recursive, tree accumulation
- values of primitive expressions:
  - numerals: the number they name
  - built-in operators: the respective machine instruction sequences
  - other names: the objects associated with the names in the environment
- special forms :: (combined) expressions that have special evaluation rules
  - e.g. =(define)= does not apply a procedure to its arguments, but associates a variable with a value
    
*** 1.1.4 Compound Procedures
- procedure definitions :: associating names (in the corresponding environment) with compound procedures
- general form of a procedure definition (in Scheme):
  - =(define (<name> <formal parameters>) <body>)=
  
*** 1.1.5 The Substitution Model for Procedure Application
- application rule for primitive procedures: built into the interpreter
- /apply/ / application rule for compound procedures :: to apply a compound procedure to arguments, evaluate the body of the procedure with each formal parameter replaced by the corresponding argument
  - so-called /substitution model/ for procedure application
  - that is, a simplified /model/, not usually literally what happens inside an interpreter
  - for instance, instead of literally replacing the formal parameters with the arguments, a /local environment/ is used
- applicative-order evaluation :: evaluate first the operator and operands, the apply the resulting procedure to the resulting arguments
- normal-order evaluation :: evaluate the operator, but don't immediately evaluate the operands. instead, substitute operand expressions for parameters, then evaluate operators as needed until you reach expressions involving only primitive operators, only then evaluate the operands
- Lisp uses applicative-order evaluation: simpler, avoids multiple evalutions, but has some limitations (e.g. for "infinite" /streams/)

*** 1.1.6 Conditional Expressions and Predicates
- /case analysis/ in Lisp: =cond=
- predicates :: procedures that return true or false, expressions that evaluate to true or false
    
**** DONE Exercise 1.1
#+begin_src scheme
  10 ; 10
  (+ 5 3 4) ; 12
  (- 9 1) ; 8
  (/ 6 2) ; 3
  (+ (* 2 4) (- 4 6)) ; 6
#+end_src

#+RESULTS:
: ;=> 6

#+begin_src scheme :exports both
  (define a 3)
  (define b (+ a 1))
  (+ a b (* a b))
#+end_src

#+RESULTS:
: ;=> 19

#+begin_src scheme :exports both
  (= a b)
#+end_src

#+RESULTS:
: ;=> #f

#+begin_src scheme :exports both
  (if (and (> b a) (< b (* a b)))
      b
      a)
#+end_src

#+RESULTS:
: ;=> 4

#+begin_src scheme :exports both
  (cond ((= a 4) 6)
        ((= b 4) (+ 6 7 a))
        (else 25))
#+end_src

#+RESULTS:
: ;=> 16

#+begin_src scheme :exports both
  (+ 2 (if (> b a) b a))
#+end_src

#+RESULTS:
: ;=> 6

#+begin_src scheme :exports both
  (* (cond ((> a b) a)
           ((< a b) b)
           (else -1))
     (+ a 1))
#+end_src

#+RESULTS:
: ;=> 16

**** DONE Exercise 1.2
#+begin_src scheme :exports both
  (/ (+ 5 4 (- 2 (- 3 (+ 6 (/ 4 5)))))
     (/ 3 (- 6 2) (- 2 7)))
#+end_src

#+RESULTS:
: ;=> -296/3

**** DONE Exercise 1.3
#+begin_src scheme :exports both
  (define (square a)
    (* a a))

  (define (sum-of-squares a b)
    (+ (square a) (square b)))

  (define (larger-squares-sum a b c)
    "Returns the sum of the squares of the two larger numbers."
    (cond ((or (<= a b) (<= a c)) (sum-of-squares b c))
          ((or (<= b a) (<= b c)) (sum-of-squares a c))
          (else (sum-of-squares a b))))

  (larger-squares-sum 2 3 4)
#+end_src

#+RESULTS:
: ;=> 25

**** DONE Exercise 1.4
For positive /b/, the procedure uses addition, otherwise subtraction as its operator.

#+begin_src scheme
  (define (a-plus-abs-b a b)
    ((if (> b 0) + -) a b))
#+end_src

#+RESULTS:
: ;=> #<void>

**** DONE Exercise 1.5
#+begin_src scheme
  (define (p) (p))

  (define (test x y)
    (if (= x 0)
        0
        y))
#+end_src

#+RESULTS:
: ;=> #<void>

=(test 0 (p))= would loop indefinitely in applicative-order evaluation (as in Scheme), because the argument gets evaluated when the function is called, not only once it's used in the body. In normal-oder evaluation, y would never get evaluated because the if-condition is true. =test= would return 0.

*** 1.1.7 Example: Square Roots using Newton's Method
Iteration can be accomplished simply using the ability to call a procedure.

#+begin_src scheme :exports both
  (define (average x y)
    (/ (+ x y) 2))

  (define (sqrt x)
    (define (improve guess)
      (average guess (/ x guess)))

    (define (good-enough? guess)
      (< (abs (- (square guess) x)) 0.001))

    (define (sqrt-iter guess)
      (if (good-enough? guess)
          guess
          (sqrt-iter (improve guess))))

    (sqrt-iter 1.0))
  
  (sqrt 9)
#+end_src

  #+RESULTS:
  : ;=> 3.00009155413138

  #+begin_src scheme :exports both
    (square (sqrt 0.001))
  #+end_src

  #+RESULTS:
  : ;=> 0.0017011851721075596

  Quite nice, but not yet perfect for small numbers.

**** DONE Exercise 1.6
#+begin_src scheme
  (define (new-if predicate then-clause else-clause)
    (cond (predicate then-clause)
          (else else-clause)))
#+end_src

#+RESULTS:
: ;=> #<void>

Because =new-if= is not a special form (unlike =if=), all the arguments get evaluated, so =sqrt-iter= would get called indefinitely if it used =new-if= instead of =if=.

**** DONE Exercise 1.7
#+begin_src scheme :exports both
  (define (better-sqrt x)
     (define (improve guess)
       (average guess (/ x guess)))

     (define (good-enough? guess old-guess)
       (< (/ (abs (- guess old-guess)) guess)
          1/10000))

     (define (sqrt-iter guess old-guess)
       (if (good-enough? guess old-guess)
           guess
           (sqrt-iter (improve guess) guess)))

     (sqrt-iter 1.0 2.0)) ; 2.0 just so the first "change" is 1

  (square (better-sqrt 0.001))
#+end_src

#+RESULTS:
: ;=> 0.001000000000000034

Better!

**** DONE Exercise 1.8
#+begin_src scheme :exports both
  (define (cube a)
    (* a a a))

  (define (cbrt x)
    (define (good-enough? guess)
      (< (abs (- (cube guess) x)) 0.001))

    (define (improve guess)
      (/ (+ (/ x (square guess))
            (* 2 guess))
         3))

    (define (iter guess)
      (if (good-enough? guess)
          guess
          (iter (improve guess))))

    (iter 1.0))

  (cbrt 27)
#+end_src

#+RESULTS:
: ;=> 3.0000005410641766

Yay!

*** 1.1.8 Procedures as Black-Box Abstractions
- local names :: the names of the procedure's formal parameters should not matter to the user of the procedure
- bound variable :: a formal parameter of a procedure, have the body of the procedure as their /scope/
- free variable :: a variable that is not bound by the procedure definition
- /block structure/ :: nesting of definitions within definitions to hide them from external use
- lexical scoping :: free variables in a procedure refer to bindings made by enclosing procedure definitions -> they get looked up in the environment in which the procedure was defined (not in the environment in which it was called, as in dynamic scoping)
  
** TODO 1.2 Procedures and the Processes They Generate [13/20]
  :PROPERTIES:
  :COOKIE_DATA: todo recursive
  :END:
*** 1.2.1 Linear Recursion and Iteration
#+begin_src scheme
  (define (factorial-recursive n)
    (if (= n 1)
        1
        (* n (factorial-recursive (- n 1)))))

  (define (factorial-iterative n)
    (define (iter product counter)
      (if (> counter n)
          product
          (iter (* counter product)
                (+ counter 1))))
    
    (iter 1 1))
#+end_src

#+RESULTS:
: ;=> #<void>
 
- recursive process :: builds up a chain of /deferred operations/, requires space to keep track of the deferred operations
- linear recursive process :: recursive process where the amount of space neeed to keep track of the deferred operations grows linearly with /n/ / is proportional to /n/, as does the amount of steps required
- iterative process :: the state is encapsulated at all times in a fixed number of /state variables/, plus a description of update behaviors, and termination condition. space requirement is fixed.
- linear iterative process :: iterative process where the number of steps grows lineraly with /n/

- A recursive /process/ is not the same as a recursive /procedure/. =factorial-iterative= has a recursive procedure definition, but the process it generates is iterative.
- To allow for iterative processes to be generated by recursive procedure definitions, an implementation needs to be /tail-recursive/ (special iteration constructs can then be omitted).
  
**** DONE Exercise 1.9
Generates a /recursive process/ for addition in terms of =inc= and =dec=:

#+begin_src scheme :session none :exports both
  (define (inc a) (+ a 1))

  (define (dec a) (- a 1))

  (define (plus a b)
    (if (= a 0)
        b
        (inc (plus (dec a) b))))

  (plus 2 3)
#+end_src

#+RESULTS:
: ;=> 5

Generates an /iterative process/ for addition in terms of =inc= and =dec=:

#+begin_src scheme :session none :exports both
  (define (inc a) (+ a 1))

  (define (dec a) (- a 1))

  (define (plus a b)
    (if (= a 0)
        b
        (plus (dec a) (inc b))))

  (plus 2 3)
#+end_src

#+RESULTS:
: ;=> 5

**** DONE Exercise 1.10 Ackermann's function
#+begin_src scheme
  (define (A x y)
    (cond ((= y 0) 0)
          ((= x 0) (* 2 y))
          ((= y 1) 2)
          (else (A (- x 1)
                   (A x (- y 1))))))

#+end_src

#+RESULTS:
: ;=> #<void>

- 2n:
#+begin_src scheme
  (define (f n) (A 0 n))
#+end_src

#+RESULTS:
: ;=> #<void>

- 2^n:
  
#+begin_src scheme
  (define (g n) (A 1 n))
#+end_src

#+RESULTS:
: ;=> #<void>

- 2^(2^n):
  
#+begin_src scheme
  (define (h n) (A 2 n))
#+end_src

#+RESULTS:
: ;=> #<void>

*** 1.2.2 Tree Recursion
**** Fibonacci
Tree-recursive process: The number of steps grows exponentially, space use linearly.
#+begin_src scheme
  (define (fib-rec n)
    (cond ((= n 0) 0)
          ((= n 1) 1)
          (else (+ (fib-rec (- n 1))
                   (fib-rec (- n 2))))))

  (fib-rec 5)
#+end_src

#+RESULTS:
: ;=> 5

Linear iterative process: The number of steps grows linearly, space use is constant.
#+begin_src scheme
  (define (fib-iter a b count)
    (if (= count 0)
        b
        (fib-iter (+ a b) a (- count 1))))
  
  (define (fib-it n)
    (fib-iter 1 0 n))

  (fib-it 5)
#+end_src

#+RESULTS:
: ;=> 5

**** Example: Counting Change
Writing a procedure that calculates how many different ways there are of changing x amount of money with n different types of coins.

#+begin_src scheme :exports both
  (define (first-denomination kinds-of-coins)
    (cond ((= kinds-of-coins 1) 1)
          ((= kinds-of-coins 2) 5)
          ((= kinds-of-coins 3) 10)
          ((= kinds-of-coins 4) 25)
          ((= kinds-of-coins 5) 50)))

  (define (cc amount kinds-of-coins)
    (cond
     ;; no money counts as 1 way of changing it
     ((= amount 0) 1)
     ;; neg money or no coin-kinds is 0 ways of changing it
     ((or (< amount 0) (= kinds-of-coins 0)) 0)
     (else (+ (cc amount
                  (- kinds-of-coins 1))
              (cc (- amount
                     (first-denomination
                      kinds-of-coins))
                  kinds-of-coins)))))

  (define (count-change amount) (cc amount 5))

  (count-change 200)
#+end_src

#+RESULTS:
: ;=> 2435

**** DONE Exercise 1.11
#+begin_src scheme :exports both :session none
  (define (func-rec n)
    (if (< n 3)
        n
        (+ (func-rec (- n 1))
           (* 2 (func-rec (- n 2)))
           (* 3 (func-rec (- n 3))))))

  (func-rec 10)
#+end_src

#+RESULTS:
: ;=> 1892

#+begin_src scheme :exports both :session none
  (define (func-iter n)
    (define (iter i prev1 prev2 prev3)
      (if (= i (+ n 1))
          prev1
          (iter (+ i 1)
                (if (< i 3)
                    i
                    (+ prev1
                       (* 2 prev2)
                       (* 3 prev3)))
                prev1
                prev2)))
    (iter 0 0 0 0))

  (func-iter 10)
#+end_src

#+RESULTS:
: ;=> 1892

***** DONE Exercise 1.12 - Pascal's Triangle
#+begin_src scheme :exports both
  ;; h: height, x: steps from left
  (define (pascal-triangle-element h x) 
    (if (or (= x 1) (= x h))
        1
        (+ (pascal-triangle-element (- h 1) (- x 1))
           (pascal-triangle-element (- h 1) x))))

  (pascal-triangle-element 22 13)
#+end_src

#+RESULTS:
: ;=> 293930

***** TODO Exercise 1.13
- ideas: =(exact-integer-sqrt 5)= is 2 with remainder of 1.
  
*** 1.2.3 Orders of Growth
- n :: parameter that measures the size of the problem
- R(n) :: the amount of resources the process requires for a problem of size /n/
- R(n) = Θ(f(n)) if there are positive constants /k1/ and /k2/ independent of /n/ such that $k1f(n) <= R(n) <= k2f(n)$ for any sufficiently large value of /n/ :: R(n) has order of growth Θ(f(n))

In other words: For any big /n/, the resources needed will be between $k1 * f(n)$  and $k2 * f(n)$ some two positive constants /k1/ and /k2/. It doesn't matter what these positive constants are, but they have to exist. But this means that for all the processes for which /R(n) = Θ(f(n))/ holds for $f(n) = n$, the same holds for $f(n) = c * n$, where c is some constant factor. That is, all processes with an order of growth of /f(n)/ also have order of growth of /f(c*n)/, that is, the two functions describe the same group of processes, so we can probably reduce it just to $f(n) = n$, or Θ(n).

- orders of growth provide only a crude description of the behavior of a process (and processes with the same order of growth can still require vastly different amounts of resources)
- but they are useful to indicate how changing the size of the problem would change the resource use of the process

- Θ(n) :: linear process, doubling n will roughly double the amount of resources
- Θ(n^2) :: expontential process, incrementing n will multiply resources by a constant factor
- Θ(log(n)) :: logarithmic process, doubling n will increase resources by a constant amount
  
**** TODO Exercise 1.14
**** DONE Exercise 1.15
- State "DONE"       from "TODO"       [2023-01-08 Sun 18:14]
  
#+begin_src scheme :exports both :results output
  (define (cube x) (* x x x))

  (define (p x)
    (display "p ")
    (- (* 3 x) (* 4 (cube x))))

  (define (sine angle)
    (if (not (> (abs angle) 0.1))
        angle
        (p (sine (/ angle 3.0)))))

  (display (sine 12.15))
#+end_src

#+RESULTS:
: ;=> p p p p p -0.39980345741334

1. =p= is applied 5 times when =(sine 12.15)= is evaluated.
2. To get the order of growth in time for =(sine a)= relative to /a/, we first note that the recursive call to =sine= is the thing that will be relevant, as both =cube= and =p= just use a constant amount of steps for each call. =sine= is called as often as is needed to repeatedly divide /angle/ by 3.0 until it (or its absolute value) is smaller or equal to 0.1. So if we triple /angle/, we will need one more step, so the order of growth is $log_3(n)$. Same goes for order of growth in space, as every call to =p= is deferred until a small enough angle is reached.
   
*** 1.2.4 Exponentiation
Linear recursive process,  Θ(n) steps, Θ(n) space:
#+begin_src scheme
  (define (expt-rec b n)
    (if (= n 0)
        1
        (* b (expt-rec b (- n 1)))))
#+end_src

#+RESULTS:
: ;=> #<void>

Linear iterative process, Θ(n) steps, Θ(1) space:
#+begin_src scheme
  (define (expt-iter b n)
    (define (iter counter product)
      (if (= counter 0)
          product
          (iter (- counter 1)
                (* b product))))
    (iter n 1))
#+end_src

#+RESULTS:
: ;=> #<void>

Logarithmic, time Θ(log n) steps, Θ(log n) space:
#+begin_src scheme
  (define (even? n)
    (= (remainder n 2) 0))

  (define (fast-expt b n)
    (cond ((= n 0) 1)
          ((even? n) (square (fast-expt b (/ n 2))))
          (else (* b (fast-expt b (- n 1))))))
#+end_src

#+RESULTS:
: ;=> #<void>

Computing $b^2n$  with =fast-expt= only needs one more multiplication than computing $b^n$. Every new step allows for (roughly) double the problem size. Therefore, its order of growth is the logarithm of /n/ to the base 2, Θ(log n). The base to which logarithms are taken does not matter (because of the arbitrary constants /k1/ and /k2/), so we just write Θ(log n). [ TODO: I don't think I understand that last sentence yet. I get why a constant factor like 2n would be equal to n, but this seems different? ]

**** DONE Exercise 1.16
- State "DONE"       from "TODO"       [2023-01-08 Sun 22:01]
#+begin_src scheme :exports both 
  (define (fast-expt-iter b n)
    (define (iter b n a)
      (cond ((= n 0) a)
            ((even? n) (iter (square b) (/ n 2) a))
            (else (iter b (- n 1) (* b a)))))
    (iter b n 1))

  (fast-expt-iter 2 2)
#+end_src

#+RESULTS:
: ;=> 4

- /invariant quantity/ :: Helpful technique for designing an iterative algorithm. In this case, /a/ * /b^n/ always stays the same (iterative algorithm: the complete state is always available), and at the end all the computation has moved "into" /a/, as b^n will be 1 when n=0, so we can return /a/.

**** DONE Exercise 1.17
- State "DONE"       from "TODO"       [2023-01-08 Sun 22:22]
#+begin_src scheme :exports both :session none
  (define (* a b)
    (if (= b 0)
        0
        (+ a (* a (- b 1)))))
#+end_src

#+RESULTS:
: ;=> #<void>

#+begin_src scheme :exports both 
  (define (double n) (* 2 n))

  (define (halve n) (/ n 2))

  (define (fast-multiplication a b)
    (cond ((= 0 b) 0)
          ((even? b) (double (fast-multiplication a (halve b))))
          (else (+ a (fast-multiplication a (- b 1))))))

  (fast-multiplication 150 231)
#+end_src

#+RESULTS:
: ;=> 34650

**** DONE Exercise 1.18  "Russian peasant multiplication"
- State "DONE"       from "TODO"       [2023-01-08 Sun 22:38]

#+begin_src scheme :exports both 
  (define (fast-multiplication-iterative a b)
    (define (iter a b z)
      (cond ((= b 0) z)
            ((even? b) (iter (double a) (halve b) z))
            (else (iter a (- b 1) (+ z a)))))
    (iter a b 0))

  (fast-multiplication-iterative 7098 9388)
#+end_src

#+RESULTS:
: ;=> 66636024

**** DONE Exercise 1.19 Fibonacci numbers in logarithmic number of steps

- State "DONE"       from "TODO"       [2023-01-09 Mon 10:31]
Transformation T for Fibonacci numbers:
=T: a <- a + b
   b <- a=

This is a special case of transformation T_pq, where p = 0 and q = 1.

=T_pq: a <- bq + aq + ap
      b <- bp + aq=

Applying a transformation T_pq twice ("squaring" it) gives:

=a2: (bp + aq) * q + (bq + aq + ap) * q + (bq + aq + ap) * p=
=b2: (bp + aq) * p + (bq + aq + ap) * q=

Which is equal to:

=a2:  b(q^2 + 2pq) + a(p^2 + q^2) +  a(q^2 + 2pq)==
=b2:  b(p^2 + q^2) + a(q^2 + 2pq)==

So it can be expressed as another transformation T with

=p' : p^2 + q^2=
=q' : q^2 + 2pq=

Used in a sucessive-squaring algorithm:

#+begin_src scheme :exports both
  (define (fib-iter a b p q count)
    (cond ((= count 0) b)
          ((even? count)
           (fib-iter a
                     b
                     (+ (square p) (square q))
                     (+ (square q) (* 2 p q))
                     (/ count 2)))
          (else (fib-iter (+ (* b q) (* a q) (* a p))
                          (+ (* b p) (* a q))
                          p
                          q
                          (- count 1)))))

  (define (fib n)
    (fib-iter 1 0 0 1 n))

  (fib 100)
#+end_src

#+RESULTS:
: ;=> 354224848179261915075

*** 1.2.5 Greatest Common Divisors

Euclid's algorithm:

#+begin_src scheme :exports both 
  (define (gcd a b)
    (if (= b 0)
        a
        (gcd b (remainder a b))))
#+end_src

#+RESULTS:
: ;=> #<void>

**** DONE Exercise 1.20
- State "DONE"       from "TODO"       [2023-01-09 Mon 12:47]
  
Euclid's algorithm =gcd= in /normal-order/ evaluation, illustrated with the subsitution method (/R/ indicates a call to =remainder=)

  #+begin_src scheme :results silent
    ;; (define (gcd a b) (if (= b 0) a (gcd b (remainder a b))))

    ;; (gcd 206 40): (if (= 40 0) XX (gcd 40 (remainder 206 40)))
    ;; (gcd 40 (remainder 206 40)): (if (= (remainder 206 40) 0)...
    ;;                            R ;   (= 6 0) ...
    ;; (gcd (remainder 206 40) (remainder 40 (remainder 206 40))):
    ;;     (if (= (remainder 40 (remainder 206 40)) 0) ...
    ;;  RR   ; (= 4 0) ...
    ;; (gcd (remainder 40 (remainder 206 40))(remainder (remainder 206 40) (remainder 40 (remainder 206 40)))):
    ;;      (if (= (remainder (remainder 206 40) (remainder 40 (remainder 206 40))) 0): ...
    ;; RRRR ; (= 2 0) ...
    ;; (gcd (remainder (remainder 206 40) (remainder 40 (remainder 206 40))) (remainder (remainder 40 (remainder 206 40)) (remainder (remainder 206 40) (remainder 40 (remainder 206 40)))))
    ;;      (if (= (remainder (remainder 40 (remainder 206 40)) (remainder (remainder 206 40) (remainder 40 (remainder 206 40)))) 0) ...
    ;; RRRRRRR ; (= 0 0)
    ;; ; -> (remainder (remainder 206 40) (remainder 40 (remainder 206 40)))
    ;; RRRR   ; 2                            
  #+end_src

  The normal-order evaluation makes 18 calls to =remainder=.

  Applicative-order evaluation:

  #+begin_src scheme :results silent
    ;; (define (gcd a b) (if (= b 0) a (gcd b (remainder a b))))
    ;;     (gcd 206 40): (if (= 40 0) 206 (gcd 40 (remainder 206 40))) ; R
    ;;     (gcd 40 6)  : (if (= 6 0) 40 (gcd 6 (remainder 40 6))) ; R
    ;;     (gcd 6 4)   : (if (= 4 0) 6 (gcd 4 (remainder 6 4))) ; R
    ;;     (gcd 4 2)   : (if (= 2 0) 4 (gcd 2 (remainder 4 2))) ; R
    ;;     (gcd 2 0)   : (if (= 0 0) 2 (gcd 0 (remainder 2 0)))
   #+end_src


The applicative-order evaluation makes 4 calls to =remainder=.

*** 1.2.6 Example: Testing for Primality

Finding the smallest integral divisor greater than 1 of /n/ (if it's /n/, then /n/ is prime):

#+begin_src scheme :exports both
  (define (divides? a b) (= (remainder b a) 0))

  (define (find-divisor n test-divisor)
    (cond ((> (square test-divisor) n) n)
          ((divides? test-divisor n) test-divisor)
          (else (find-divisor n (+ test-divisor 1)))))

  (define (smallest-divisor n)
    (find-divisor n 2))

  (define (prime? n)
    (= n (smallest-divisor n)))

  (prime? 29)
#+end_src

#+RESULTS:
: ;=> #t

This algorithm checks all numbers between 1 and =(sqrt n)=, so it has order of growth Θ(√n). It only has to check up to =(sqrt n)=, because if /d/ is a divisor of /n/, then /n/d/ is as well, but it's not possible for both of them to be bigger than =(sqrt n)= (that would be higher than =(expt (sqrt n) 2)=, so higher than /n/). (So, any divisors bigger than =(sqrt n)= already get "caught" via their smaller counterpart.)

The Fermat Test:

- Fermat's Little Theorem :: If /n/ is a prime number and /a/ is any positive integer less than /n/, then /a/ raised to the /n/-th power is congurent to /a/ modulo /n/ (= has the same remainder as /a/ when divided by /n/).

  /In general/ (but not always!), non-prime /n/ will not satisfy this theorem. From this, we can devise a /probabilistic/ algorithm to test for primality, by checking more and more random integers smaller than /n/ for alignment with Fermat's Little Theorem.

  First, computing the exponential of a number modulo another number (using successive squaring):

  #+begin_src scheme :exports both 
    (define (expmod base exp m)
      (cond ((= exp 0) 1)
            ((even? exp) (remainder (square (expmod base (/ exp 2) m)) m))
            (else (remainder (* base (expmod base (- exp 1) m)) m))))

    (expmod 2 4 9)
  #+end_src

  #+RESULTS:
  : ;=> 7

The fermat test now takes a random number /a/ between 1 and /n/-1 and check if the /n/-th power of /a/ modulo /n/ is /a/.

#+begin_src scheme :exports both
  (define (fermat-test n)
    (define (try-it a)
      (= (expmod a n n) a))
    (try-it (+ 1 (random (- n 1)))))
#+end_src

#+RESULTS:
: ;=> #<void>

Now, we can run this as often as we want, to get more and more sure of our answer about the primality of n:

#+begin_src scheme :exports both 
  (define (fast-prime? n times)
    (cond ((= times 0) #t)
          ((fermat-test n) (fast-prime? n (- times 1)))
          (else #f)))

  (fast-prime? 87083 100)
#+end_src

#+RESULTS:
: ;=> #t

This algorithm is /probabilisitic/. While failing the Fermat test is a /certain/ indication that /n/ is not prime, passing our algorithm makes this not certain, but only very probable. What's more, there are some very few numbers (/Carmichael numbers/) that fully fool the Fermat test, they are not prime but satisfy Fermat's relation (so even if we test /all/ integers smaller than /n/, we can still not be sure.) But there are some alternative algorithms that fix this, so that the probability really increases with every additional check.

**** DONE Exercise 1.21
- State "DONE"       from "TODO"       [2023-01-09 Mon 13:32]
  
#+begin_src scheme :exports both
  (smallest-divisor 199)
#+end_src

#+RESULTS:
: ;=> 199

#+begin_src scheme :exports both 
  (smallest-divisor 1999)
#+end_src

#+RESULTS:
: ;=> 1999

#+begin_src scheme :exports both 
  (smallest-divisor 19999)
#+end_src

#+RESULTS:
: ;=> 7

Yoo...

#+begin_src scheme :exports both 
 (/ 19999 7)
#+end_src

#+RESULTS:
: ;=> 2857

**** DONE Exercise 1.22
- State "DONE"       from "TODO"       [2023-01-09 Mon 14:21]
#+begin_src scheme :exports both
  (define (report-prime n elapsed-time)
    (newline)
    (display n)
    (display " *** ")
    (display elapsed-time))

  (define (start-prime-test n start-time)
    (if (prime? n)
        (report-prime n (time-difference (current-time) start-time))
        #f))

  (define (timed-prime-test n)
    (start-prime-test n (current-time)))
#+end_src

#+RESULTS:
: ;=> #<void>

#+begin_src scheme :exports both :results output
  (define (search-for-primes start end count)
    (cond ((>= start end) nil)
          ((= count 0) nil)
          ((even? start) (search-for-primes (+ 1 start) end count))
          (else (if (timed-prime-test start)
                    (search-for-primes (+ 2 start) end (- count 1))
                    (search-for-primes (+ 2 start) end count)))))
  
  (search-for-primes 1000 2000 3)
#+end_src

#+RESULTS:
: ;=> 
: 1009 *** #<time-duration 0.000001987>
: 1013 *** #<time-duration 0.000001884>
: 1019 *** #<time-duration 0.000001944>

#+begin_src scheme :exports both :results output
  (search-for-primes 10000 12000 3)
#+end_src

#+RESULTS:
: ;=> 
: 10007 *** #<time-duration 0.000005920>
: 10009 *** #<time-duration 0.000005983>
: 10037 *** #<time-duration 0.000005777>

#+begin_src scheme :exports both :results output
  (search-for-primes 100000 120000 3)
#+end_src

#+RESULTS:
: ;=> 
: 100003 *** #<time-duration 0.000018127>
: 100019 *** #<time-duration 0.000018072>
: 100043 *** #<time-duration 0.000018015>

How do the measured times match up with the prediction one could get from the Θ(√n) order of growth of the algorithm?

#+begin_src scheme :exports both 
(* (sqrt 10) 2000)
#+end_src

#+RESULTS:
: ;=> 6324.55533035135

My 10,000 area primes seem to have taken around as long as predicted. (But the times vary a lot for each re-evaluation on my system, sometimes it doesn't match at all and can, for example, take up to 2 times longer than expected.) Note that the timings will be updated every time I reevaluate the buffer with /org-babel/, but my manual calculation here is fixed to a rough time I took once.

#+begin_src scheme :exports both 
(* (sqrt 10) 6000)
#+end_src

#+RESULTS:
: ;=> 18973.66599105405

For the 100,000 area primes the times seem to match the prediction quite well (and pretty stably so), relative to the 10,000 times.

Is my result compatible with the notion that programs on my machine run in time proportional to the number of steps required for the computation? I guess this holds true for large number of steps, wiht low number of steps there is sometimes a mismatch, maybe caused by some constant overhead? But then why does that result in a doubling of the expected times?

**** DONE Exercise 1.23
- State "DONE"       from "TODO"       [2023-01-09 Mon 14:25]
#+begin_src scheme :exports both 
       (define (next n) (if (= n 2) 3 (+ n 2)))

       (define (find-divisor-modified n test-divisor)
         (cond ((> (square test-divisor) n) n)
               ((divides? test-divisor n) test-divisor)
               (else (find-divisor-modified n (next test-divisor)))))

       (define (smallest-divisor-modified n)
         (find-divisor-modified n 2))

       (define (prime-modified? n)
         (= n (smallest-divisor-modified n)))

        (define (report-prime-modified n elapsed-time)
         (newline)
         (display n)
         (display " *** ")
         (display elapsed-time))

       (define (start-prime-test-modified n start-time)
         (if (prime-modified? n)
             (report-prime-modified
              n (time-difference (current-time) start-time))
             #f))

       (define (timed-prime-test-modified n)
         (start-prime-test-modified n (current-time)))

       (define (search-for-primes-modified start end count)
         (cond ((>= start end) nil)
               ((= count 0) nil)
               ((even? start) (search-for-primes-modified
                               (+ 1 start) end count))
               (else (if (timed-prime-test-modified start)
                         (search-for-primes-modified
                          (+ 2 start) end (- count 1))
                         (search-for-primes-modified
                          (+ 2 start) end count)))))    
#+end_src

#+RESULTS:
: ;=> #<void>

#+begin_src scheme :exports both :results output
  (search-for-primes-modified 1000 2000 3)  
#+end_src

#+RESULTS:
: ;=> 
: 1009 *** #<time-duration 0.000001433>
: 1013 *** #<time-duration 0.000001313>
: 1019 *** #<time-duration 0.000001236>

#+begin_src scheme :exports both :results output
  (search-for-primes-modified 10000 12000 3)
#+end_src

#+RESULTS:
: ;=> 
: 10007 *** #<time-duration 0.000003568>
: 10009 *** #<time-duration 0.000003639>
: 10037 *** #<time-duration 0.000003281>

#+begin_src scheme :exports both :results output
  (search-for-primes-modified 100000 120000 3)
#+end_src

#+RESULTS:
: ;=> 
: 100003 *** #<time-duration 0.000003932>
: 100019 *** #<time-duration 0.000003730>
: 100043 *** #<time-duration 0.000003712>

The modification halved the number of steps. Time varies significantly for each re-evaluation on my system, I don't know why. This makes conclusions hard. But for the 1000 area primes, the modification appears to have made it 4 times faster (but sometimes not). For 10,000 area primes, the time got roughly halved (sometimes not). For 100,000 area primes, there is sometimes no noticeable benefit, but sometimes it even goes to around 4 to 5 times faster! So yeah, uncertain conclusion, certainly no simple ratio. 
**** TODO Exercise 1.24
**** TODO Exercise 1.25
**** TODO Exercise 1.26
**** TODO Exercise 1.27
**** TODO Exercise 1.28
** TODO 1.3 Formulating Abstractions with Higher-Order Procedures [0/18]
  :PROPERTIES:
  :COOKIE_DATA: todo recursive
  :END:
*** 1.3.1 Procedures as Arguments
**** TODO Exercise 1.29
**** TODO Exercise 1.30
**** TODO Exercise 1.31
**** TODO Exercise 1.32
**** TODO Exercise 1.33
*** 1.3.2 Constructing Procedures Using =lambda=
**** TODO Exercise 1.34
*** 1.3.3 Procedures as General Methods
**** TODO Exercise 1.35
**** TODO Exercise 1.36
**** TODO Exercise 1.37
**** TODO Exercise 1.38
**** TODO Exercise 1.39
*** 1.3.4 Procedures as Returned Values
**** TODO Exercise 1.40
**** TODO Exercise 1.41
**** TODO Exercise 1.42
**** TODO Exercise 1.43
**** TODO Exercise 1.44
**** TODO Exercise 1.45
**** TODO Exercise 1.46
* Chapter 2
* Chapter 3
* Chapter 4
* Chapter 5
